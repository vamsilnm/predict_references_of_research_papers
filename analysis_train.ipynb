{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "information_train = pd.read_csv('train/information_train.csv',delimiter='\\t')\n",
    "train = pd.read_csv('train/train.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fitting TFIDF Vectorizer over complete corpus\n",
    "tfidf_vectorizer_title = TfidfVectorizer(analyzer='word',ngram_range=(1,3),stop_words='english',norm='l2',max_features=50)\n",
    "title_vectors = tfidf_vectorizer_title.fit_transform(information_train['article_title'])\n",
    "\n",
    "tfidf_vectorizer_abstract = TfidfVectorizer(analyzer='word',ngram_range=(1,2),stop_words='english',norm='l2',max_features=200)\n",
    "abstract_vectors = tfidf_vectorizer_abstract.fit_transform(information_train['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_numbers = list(information_train.set.value_counts().index)\n",
    "# test_set_numbers = list(information_test.set.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_set_wise_data(set_number):\n",
    "    information_for_this_set = information_train[information_train.set == set_number]\n",
    "    information_for_this_set = information_for_this_set.head(20)\n",
    "    information_for_this_set.reset_index(drop=True,inplace=True)\n",
    "    information_for_this_set = information_for_this_set[['abstract','article_title','pmid','pub_date']]\n",
    "\n",
    "    return information_for_this_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set_wise_train = {}\n",
    "for each_set in train_set_numbers:\n",
    "    data_set_wise_train[each_set] = get_set_wise_data(each_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>article_title</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pub_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996 is polio awareness year. This paper revie...</td>\n",
       "      <td>Poliomyelitis.</td>\n",
       "      <td>8944203</td>\n",
       "      <td>1996-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The aim of this study was to determine the app...</td>\n",
       "      <td>General primer-mediated polymerase chain react...</td>\n",
       "      <td>1370845</td>\n",
       "      <td>1992-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We describe a rapid method for extraction and ...</td>\n",
       "      <td>Rapid diagnosis of enterovirus infection by ma...</td>\n",
       "      <td>8380182</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have developed a simple, rapid, and reliabl...</td>\n",
       "      <td>Rapid and simple method for purification of nu...</td>\n",
       "      <td>1691208</td>\n",
       "      <td>1990-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enteroviruses were specifically detected in cr...</td>\n",
       "      <td>Specific detection of enteroviruses in clinica...</td>\n",
       "      <td>2155917</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  1996 is polio awareness year. This paper revie...   \n",
       "1  The aim of this study was to determine the app...   \n",
       "2  We describe a rapid method for extraction and ...   \n",
       "3  We have developed a simple, rapid, and reliabl...   \n",
       "4  Enteroviruses were specifically detected in cr...   \n",
       "\n",
       "                                       article_title     pmid    pub_date  \n",
       "0                                     Poliomyelitis.  8944203  1996-11-01  \n",
       "1  General primer-mediated polymerase chain react...  1370845  1992-01-01  \n",
       "2  Rapid diagnosis of enterovirus infection by ma...  8380182  1993-01-01  \n",
       "3  Rapid and simple method for purification of nu...  1691208  1990-03-01  \n",
       "4  Specific detection of enteroviruses in clinica...  2155917  1990-02-01  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_wise_train[16].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merging_data_frame(particular_row_series,df_remaining_rows):\n",
    "    \n",
    "    duplicate_frequency = df_remaining_rows.shape[0] - 1\n",
    "    df_remaining_rows = df_remaining_rows.rename(columns={'abstract': 'abstract_1', 'article_title': 'article_title_1','pmid': 'pmid_1','pub_date': 'pub_date_1'})\n",
    "    df_particular_row = pd.DataFrame(particular_row_series).transpose()\n",
    "    df_particular_row = df_particular_row.append([df_particular_row]*duplicate_frequency,ignore_index=True)\n",
    "    \n",
    "\n",
    "    df_particular_row.reset_index(drop=True, inplace=True)\n",
    "    df_remaining_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    result = pd.concat([df_particular_row, df_remaining_rows], axis=1)\n",
    "    return result\n",
    "#     master_frames.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data_train = {}\n",
    "for each_set in train_set_numbers:\n",
    "    master_frames = []\n",
    "    this_set_data = data_set_wise_train[each_set]\n",
    "    for index,row in this_set_data.iterrows():\n",
    "        master_frames.append(merging_data_frame(this_set_data.iloc[index],this_set_data.drop(this_set_data.index[[index]])))\n",
    "    \n",
    "    combined_df = pd.concat(master_frames,ignore_index=True)\n",
    "    combined_df.pub_date = pd.to_datetime(combined_df.pub_date)\n",
    "    combined_df.pub_date_1 = pd.to_datetime(combined_df.pub_date_1)\n",
    "    combined_df['differnce_days'] = combined_df['pub_date'] - combined_df['pub_date_1']\n",
    "    combined_df['differnce_days'] = combined_df['differnce_days'] / (np.timedelta64(1, 'D'))\n",
    "    combined_df = combined_df[combined_df > 0].dropna()\n",
    "    combined_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    combined_data_train[each_set] = combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_abstract(row):\n",
    "    \n",
    "    index_1 = information_train.pmid[information_train.pmid == row['pmid']].index.tolist()[0]\n",
    "    index_2 = information_train.pmid[information_train.pmid == row['pmid_1']].index.tolist()[0]\n",
    "    similarity_score = cosine_similarity(abstract_vectors[index_1],abstract_vectors[index_2])\n",
    "    return similarity_score[0][0]\n",
    "    \n",
    "def cosine_similarity_title(row):\n",
    "    \n",
    "    index_1 = information_train.pmid[information_train.pmid == row['pmid']].index.tolist()[0]\n",
    "    index_2 = information_train.pmid[information_train.pmid == row['pmid_1']].index.tolist()[0]\n",
    "    similarity_score = cosine_similarity(title_vectors[index_1],title_vectors[index_2])\n",
    "    return similarity_score[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_set in train_set_numbers:\n",
    "    combined_data_train[each_set]['title_similarity'] = combined_data_train[each_set].apply(cosine_similarity_title,axis=1)\n",
    "    combined_data_train[each_set]['abstract_similarity'] = combined_data_train[each_set].apply(cosine_similarity_abstract,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>article_title</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>abstract_1</th>\n",
       "      <th>article_title_1</th>\n",
       "      <th>pmid_1</th>\n",
       "      <th>pub_date_1</th>\n",
       "      <th>differnce_days</th>\n",
       "      <th>title_similarity</th>\n",
       "      <th>abstract_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996 is polio awareness year. This paper revie...</td>\n",
       "      <td>Poliomyelitis.</td>\n",
       "      <td>8944203</td>\n",
       "      <td>1996-11-01</td>\n",
       "      <td>The aim of this study was to determine the app...</td>\n",
       "      <td>General primer-mediated polymerase chain react...</td>\n",
       "      <td>1370845</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996 is polio awareness year. This paper revie...</td>\n",
       "      <td>Poliomyelitis.</td>\n",
       "      <td>8944203</td>\n",
       "      <td>1996-11-01</td>\n",
       "      <td>We describe a rapid method for extraction and ...</td>\n",
       "      <td>Rapid diagnosis of enterovirus infection by ma...</td>\n",
       "      <td>8380182</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract   article_title     pmid  \\\n",
       "0  1996 is polio awareness year. This paper revie...  Poliomyelitis.  8944203   \n",
       "1  1996 is polio awareness year. This paper revie...  Poliomyelitis.  8944203   \n",
       "\n",
       "    pub_date                                         abstract_1  \\\n",
       "0 1996-11-01  The aim of this study was to determine the app...   \n",
       "1 1996-11-01  We describe a rapid method for extraction and ...   \n",
       "\n",
       "                                     article_title_1   pmid_1 pub_date_1  \\\n",
       "0  General primer-mediated polymerase chain react...  1370845 1992-01-01   \n",
       "1  Rapid diagnosis of enterovirus infection by ma...  8380182 1993-01-01   \n",
       "\n",
       "   differnce_days  title_similarity  abstract_similarity  \n",
       "0          1766.0               0.0             0.063952  \n",
       "1          1400.0               0.0             0.113354  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_train[16].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_refernce(row):\n",
    "    index_train = train.pmid[train.pmid == row['pmid']].index.tolist()[0]\n",
    "    references_string = train.iloc[index_train]['ref_list']\n",
    "    references_string_clean = references_string.replace('[','').replace(']','').replace('\\'','').split(sep=',')\n",
    "    references_list = list(map(int, references_string_clean))\n",
    "    \n",
    "    if row['pmid_1'] in references_list:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for each_set in train_set_numbers:\n",
    "    combined_data_train[each_set]['is_reference'] = combined_data_train[each_set].apply(is_refernce,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>article_title</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>abstract_1</th>\n",
       "      <th>article_title_1</th>\n",
       "      <th>pmid_1</th>\n",
       "      <th>pub_date_1</th>\n",
       "      <th>differnce_days</th>\n",
       "      <th>title_similarity</th>\n",
       "      <th>abstract_similarity</th>\n",
       "      <th>is_reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996 is polio awareness year. This paper revie...</td>\n",
       "      <td>Poliomyelitis.</td>\n",
       "      <td>8944203</td>\n",
       "      <td>1996-11-01</td>\n",
       "      <td>The aim of this study was to determine the app...</td>\n",
       "      <td>General primer-mediated polymerase chain react...</td>\n",
       "      <td>1370845</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996 is polio awareness year. This paper revie...</td>\n",
       "      <td>Poliomyelitis.</td>\n",
       "      <td>8944203</td>\n",
       "      <td>1996-11-01</td>\n",
       "      <td>We describe a rapid method for extraction and ...</td>\n",
       "      <td>Rapid diagnosis of enterovirus infection by ma...</td>\n",
       "      <td>8380182</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996 is polio awareness year. This paper revie...</td>\n",
       "      <td>Poliomyelitis.</td>\n",
       "      <td>8944203</td>\n",
       "      <td>1996-11-01</td>\n",
       "      <td>We have developed a simple, rapid, and reliabl...</td>\n",
       "      <td>Rapid and simple method for purification of nu...</td>\n",
       "      <td>1691208</td>\n",
       "      <td>1990-03-01</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996 is polio awareness year. This paper revie...</td>\n",
       "      <td>Poliomyelitis.</td>\n",
       "      <td>8944203</td>\n",
       "      <td>1996-11-01</td>\n",
       "      <td>Enteroviruses were specifically detected in cr...</td>\n",
       "      <td>Specific detection of enteroviruses in clinica...</td>\n",
       "      <td>2155917</td>\n",
       "      <td>1990-02-01</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996 is polio awareness year. This paper revie...</td>\n",
       "      <td>Poliomyelitis.</td>\n",
       "      <td>8944203</td>\n",
       "      <td>1996-11-01</td>\n",
       "      <td>Enteroviruses are among the most common causes...</td>\n",
       "      <td>Enzymatic RNA amplification of the enteroviruses.</td>\n",
       "      <td>2157735</td>\n",
       "      <td>1990-03-01</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract   article_title     pmid  \\\n",
       "0  1996 is polio awareness year. This paper revie...  Poliomyelitis.  8944203   \n",
       "1  1996 is polio awareness year. This paper revie...  Poliomyelitis.  8944203   \n",
       "2  1996 is polio awareness year. This paper revie...  Poliomyelitis.  8944203   \n",
       "3  1996 is polio awareness year. This paper revie...  Poliomyelitis.  8944203   \n",
       "4  1996 is polio awareness year. This paper revie...  Poliomyelitis.  8944203   \n",
       "\n",
       "    pub_date                                         abstract_1  \\\n",
       "0 1996-11-01  The aim of this study was to determine the app...   \n",
       "1 1996-11-01  We describe a rapid method for extraction and ...   \n",
       "2 1996-11-01  We have developed a simple, rapid, and reliabl...   \n",
       "3 1996-11-01  Enteroviruses were specifically detected in cr...   \n",
       "4 1996-11-01  Enteroviruses are among the most common causes...   \n",
       "\n",
       "                                     article_title_1   pmid_1 pub_date_1  \\\n",
       "0  General primer-mediated polymerase chain react...  1370845 1992-01-01   \n",
       "1  Rapid diagnosis of enterovirus infection by ma...  8380182 1993-01-01   \n",
       "2  Rapid and simple method for purification of nu...  1691208 1990-03-01   \n",
       "3  Specific detection of enteroviruses in clinica...  2155917 1990-02-01   \n",
       "4  Enzymatic RNA amplification of the enteroviruses.  2157735 1990-03-01   \n",
       "\n",
       "   differnce_days  title_similarity  abstract_similarity  is_reference  \n",
       "0          1766.0               0.0             0.063952             1  \n",
       "1          1400.0               0.0             0.113354             1  \n",
       "2          2437.0               0.0             0.000000             0  \n",
       "3          2465.0               0.0             0.050657             0  \n",
       "4          2437.0               0.0             0.000000             0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_train[16].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['differnce_days', 'title_similarity', 'abstract_similarity'], dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = combined_data_train[16].select_dtypes(['float64', 'int64', 'uint8']).columns.drop('is_reference').drop('pmid_1')\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = combined_data_train[16].select_dtypes(['float64', 'int64', 'uint8']).columns.drop('is_reference').drop('pmid_1')\n",
    "\n",
    "\n",
    "y_train = combined_data_train[16].is_reference\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1,\n",
    "    'lambda': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 0\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(data=combined_data_train[16][predictors], label= y_train)\n",
    "\n",
    "\n",
    "num_rounds = 10000\n",
    "\n",
    "model_cv = xgb.cv(xgb_params, dtrain, num_rounds, nfold=10, early_stopping_rounds=20, verbose_eval=1)\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round = 44)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 16))\n",
    "xgb.plot_importance(model, height=0.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def building_models(set_number):\n",
    "    this_set_data = combined_data_train[set_number]\n",
    "    logisticRegr = LogisticRegression()\n",
    "    \n",
    "    x_train = this_set_data[['title_similarity','abstract_similarity','differnce_days']]\n",
    "    y_train = this_set_data['is_reference']\n",
    "    logisticRegr.fit(x_train, y_train)\n",
    "    \n",
    "    filename = 'model_'+str(set_number)+'_.sav'\n",
    "    pickle.dump(logisticRegr, open(filename, 'wb'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824468085106\n"
     ]
    }
   ],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(logisticRegr, open(filename, 'wb'))\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(x_train,y_train)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_references_list(set_number):\n",
    "    \n",
    "    data_with_reference_1 = combined_data_train[set_number][combined_data_train[set_number].is_reference== 1]\n",
    "    data_with_reference_1 = data_with_reference_1[['pmid','pmid_1']]\n",
    "    data_with_references_series = data_with_reference_1.groupby('pmid')['pmid_1'].apply(list)\n",
    "    data_with_references_data_frame = pd.DataFrame({'pmid':data_with_references_series.index, 'references':data_with_references_series.values})\n",
    "    \n",
    "    return data_with_references_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_references_list = {}\n",
    "for each_set in train_set_numbers:\n",
    "    aggregate_references_list[each_set] = get_references_list(each_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17003490</td>\n",
       "      <td>[1713021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17554300</td>\n",
       "      <td>[17554260]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17579875</td>\n",
       "      <td>[17591968, 16718704, 17003490]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17591968</td>\n",
       "      <td>[17003490]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17943122</td>\n",
       "      <td>[17554300]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                      references\n",
       "0  17003490                       [1713021]\n",
       "1  17554300                      [17554260]\n",
       "2  17579875  [17591968, 16718704, 17003490]\n",
       "3  17591968                      [17003490]\n",
       "4  17943122                      [17554300]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_references_list[14].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = combined_data_train[16][combined_data_train[16].is_reference== 1]\n",
    "sample_df = sample_df[['pmid','pmid_1']]\n",
    "sample_df = sample_df.groupby('pmid')['pmid_1'].apply(list)\n",
    "result = pd.DataFrame({'pmid':sample_df.index, 'references':sample_df.values})\n",
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
